{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import time\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm import create_model\n",
    "import cv2\n",
    "import json\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=2\n",
    "img_size=512\n",
    "label_map=json.load(open('he_label_map.json'))\n",
    "tf = ToTensor()\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "def createDirectory(directory):\n",
    "    \"\"\"_summary_\n",
    "        create Directory\n",
    "    Args:\n",
    "        directory (string): file_path\n",
    "    \"\"\"    \n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "        \n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list,img_size,json_file=None):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "        self.json_label=json_file\n",
    "        self.img_size = img_size    \n",
    "        \n",
    "    def trans(self,image,label):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            label = transform(label)\n",
    "            image = transform(image)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            label = transform(label)\n",
    "            image = transform(image)\n",
    "            \n",
    "        return image,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    \n",
    "    def random_crop(self, image,label):\n",
    "        h, w = image.shape[1:3]\n",
    "        r = self.img_size / min(h, w)\n",
    "        \n",
    "        # 이미지가 input_size보다 큰 경우 (r < 1) -> 랜덤 크롭\n",
    "        if r < 1:\n",
    "            # 안전하게 크롭 범위 계산\n",
    "            max_h = max(0, h - self.img_size)\n",
    "            max_w = max(0, w - self.img_size)\n",
    "            h1 = random.randint(0, max_h) if max_h > 0 else 0\n",
    "            w1 = random.randint(0, max_w) if max_w > 0 else 0\n",
    "            image = image[:,h1:h1 + self.img_size, w1:w1 + self.img_size]\n",
    "            label = label[:,h1:h1 + self.img_size, w1:w1 + self.img_size]\n",
    "        else:\n",
    "            # 이미지가 input_size보다 작거나 같은 경우 (r >= 1) -> 패딩\n",
    "            h1 = 0\n",
    "            w1 = 0\n",
    "            pad_image = torch.ones((3,self.img_size, self.img_size), dtype=torch.uint8)*255\n",
    "            pad_label=torch.zeros((len(self.json_label),self.img_size, self.img_size), dtype=torch.uint8)\n",
    "            pad_image[:,:min(h,self.img_size), :min(w,self.img_size)] = image[:,:min(h,self.img_size), :min(w,self.img_size)]\n",
    "            pad_label[:,:min(h,self.img_size), :min(w,self.img_size)] = label[:,:min(h,self.img_size), :min(w,self.img_size)]\n",
    "            image = pad_image\n",
    "            label=pad_label\n",
    "        return image, label\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image=torch.from_numpy(np.array(Image.open(self.img_path[idx]).convert('RGB')))\n",
    "        image=image.permute(2,0,1)/255.0\n",
    "        image=image*2.0-1.0\n",
    "        label_temp=255-np.array(Image.open(self.label[idx]))+1\n",
    "        label=np.zeros((len(self.json_label),label_temp.shape[0],label_temp.shape[1]),dtype=np.uint8)\n",
    "        for i in range(len(self.json_label)):\n",
    "            label[i,:,:][label_temp==list(self.json_label.values())[i]]=1\n",
    "        label=torch.from_numpy(label)\n",
    "        image,label=self.random_crop(image,label)\n",
    "\n",
    "        image,label = self.trans(image,label)\n",
    "        return image,label\n",
    "\n",
    "img_path='../../data/IGNITE/images/he/'\n",
    "img_list=glob(img_path+'*.png')\n",
    "mask_list=[i.replace('/images','/annotations') for i in img_list]\n",
    "train_img_list,test_img_list,train_mask_list,test_mask_list=train_test_split(img_list,mask_list,test_size=0.2,random_state=42)\n",
    "\n",
    "train_dataset = CustomDataset(train_img_list, train_mask_list,img_size,json_file=label_map)\n",
    "\n",
    "test_dataset = CustomDataset(test_img_list, test_mask_list,img_size,json_file=label_map)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c975ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Segformer(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=len(label_map),                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "def dice_loss(pred, target, num_classes=len(label_map)):\n",
    "    smooth = 1e-6\n",
    "    dice_per_class = torch.zeros((len(pred),num_classes)).to(pred.device)\n",
    "    pred=F.softmax(pred,dim=1)\n",
    "    for i in range(len(pred)):\n",
    "        for class_id in range(num_classes):\n",
    "            pred_class = pred[i, class_id, ...]\n",
    "            target_class = target[i, class_id, ...]\n",
    "            \n",
    "            intersection = torch.sum(pred_class * target_class)\n",
    "            A_sum = torch.sum(pred_class * pred_class)\n",
    "            B_sum = torch.sum(target_class * target_class)\n",
    "            dice_per_class[i,class_id] =(2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "\n",
    "    return 1-dice_per_class.mean()\n",
    "summary(model,(batch_size,3,img_size,img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1684a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset[0] 데이터 확인 및 시각화\n",
    "sample_image, sample_label = train_dataset[4]\n",
    "\n",
    "print(f\"Image shape: {sample_image.shape}\")\n",
    "print(f\"Label shape: {sample_label.shape}\")\n",
    "print(f\"Image range: [{sample_image.min():.3f}, {sample_image.max():.3f}]\")\n",
    "print(f\"Label unique values: {torch.unique(sample_label)}\")\n",
    "\n",
    "# 17개 클래스를 RGB 색상으로 매핑\n",
    "colors = [\n",
    "    [0, 0, 0],        # 0: Unannotated - Black\n",
    "    [255, 255, 255],  # 1: Background - White\n",
    "    [255, 0, 0],      # 2: Tumor epithelium - Red\n",
    "    [255, 165, 0],    # 3: Reactive epithelium - Orange\n",
    "    [0, 255, 0],      # 4: Stroma - Green\n",
    "    [255, 255, 0],    # 5: Inflammation - Yellow\n",
    "    [0, 255, 255],    # 6: Alveolar tissue - Cyan\n",
    "    [255, 192, 203],  # 7: Fatty tissue - Pink\n",
    "    [128, 0, 128],    # 8: Necrotic tissue - Purple\n",
    "    [255, 0, 255],    # 9: Erythrocytes - Magenta\n",
    "    [0, 0, 255],      # 10: Bronchial epithelium - Blue\n",
    "    [165, 42, 42],    # 11: Mucus/Plasma/Fluids - Brown\n",
    "    [128, 128, 128],  # 12: Cartilage/Bone - Gray\n",
    "    [0, 128, 0],      # 13: Macrophages - Dark Green\n",
    "    [128, 0, 0],      # 14: Muscle - Maroon\n",
    "    [255, 20, 147],   # 15: Liver - Deep Pink\n",
    "    [255, 140, 0]     # 16: Keratinization - Dark Orange\n",
    "]\n",
    "\n",
    "# 이미지를 [0, 1] 범위로 정규화 (현재 [-1, 1] 범위)\n",
    "normalized_image = (sample_image + 1.0) / 2.0\n",
    "\n",
    "# 라벨을 argmax로 변환하여 클래스 인덱스 얻기\n",
    "label_indices = torch.argmax(sample_label, 0)\n",
    "\n",
    "# 라벨을 RGB 색상으로 변환\n",
    "label_rgb = torch.zeros((3, img_size, img_size))\n",
    "for class_id in range(len(label_map)):\n",
    "    mask = (label_indices == class_id).float()\n",
    "    label_rgb[0] += mask * colors[class_id][0] / 255.0\n",
    "    label_rgb[1] += mask * colors[class_id][1] / 255.0\n",
    "    label_rgb[2] += mask * colors[class_id][2] / 255.0\n",
    "\n",
    "# 오버레이 생성 (이미지 70% + 라벨 30%)\n",
    "overlay = normalized_image * 0.7 + label_rgb * 0.3\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# 원본 이미지\n",
    "axes[0].imshow(normalized_image.permute(1, 2, 0))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 라벨 마스크\n",
    "axes[1].imshow(label_rgb.permute(1, 2, 0))\n",
    "axes[1].set_title('Label Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 오버레이\n",
    "axes[2].imshow(overlay.permute(1, 2, 0))\n",
    "axes[2].set_title('Overlay (Image + Label)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 각 클래스별 픽셀 수 확인\n",
    "print(\"\\nClass distribution:\")\n",
    "for class_name, class_id in label_map.items():\n",
    "    pixel_count = (label_indices == class_id).sum().item()\n",
    "    percentage = (pixel_count / (img_size * img_size)) * 100\n",
    "    if pixel_count > 0:\n",
    "        print(f\"{class_name} (ID: {class_id}): {pixel_count} pixels ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "\n",
    "MIN_loss=5000\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-3)\n",
    "metrics = defaultdict(float)\n",
    "for epoch in range(1000):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    for x, y in train:\n",
    "        model.train()\n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "        predict = model(x).to(device)\n",
    "        cost = dice_loss(predict, y) # cost 구함\n",
    "        acc=1-cost.item()\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.step() \n",
    "        running_loss += cost.item()\n",
    "        acc_loss+=acc\n",
    "        y = y.to('cpu')\n",
    "\n",
    "        x=x.to('cpu')\n",
    "        train.set_description(f\"epoch: {epoch+1}/{1000} Step: {count+1} dice_loss : {running_loss/count:.4f} dice_score: {1-running_loss/count:.4f}\")\n",
    "    train_loss_list.append((running_loss/count))\n",
    "    train_acc_list.append((acc_loss/count))\n",
    "#test\n",
    "    val=tqdm(test_dataloader)\n",
    "    model.eval()\n",
    "    count=0\n",
    "    val_running_loss=0.0\n",
    "    acc_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val:\n",
    "            y = y.to(device).float()\n",
    "            count+=1\n",
    "            x=x.to(device).float()\n",
    "            \n",
    "            predict = model(x).to(device)\n",
    "            cost = dice_loss(predict, y) # cost 구함\n",
    "            acc=1-cost.item()\n",
    "            val_running_loss+=cost.item()\n",
    "            acc_loss+=acc\n",
    "            y = y.to('cpu')\n",
    "            x=x.to('cpu')\n",
    "            val.set_description(f\"test epoch: {epoch+1}/{1000} Step: {count+1} dice_loss : {val_running_loss/count:.4f}  dice_score: {1-val_running_loss/count:.4f}\")\n",
    "        val_loss_list.append((val_running_loss/count))\n",
    "        val_acc_list.append((acc_loss/count))\n",
    "        \n",
    "    if MIN_loss>(val_running_loss/count):\n",
    "        createDirectory('../../model/HnE_Organizational_Segmentation/')\n",
    "        torch.save(model.state_dict(), '../../model/HnE_Organizational_Segmentation/check.pt')\n",
    "        MIN_loss=(val_running_loss/count)\n",
    "    \n",
    "    # 예측 마스크 생성 (17개 클래스를 색상으로 매핑)\n",
    "    pred_mask1 = torch.argmax(predict[0], 0).cpu()\n",
    "    pred_mask = torch.zeros((3, img_size, img_size))\n",
    "    \n",
    "    # 17개 클래스를 RGB 색상으로 매핑\n",
    "    colors = [\n",
    "        [0, 0, 0],        # 0: Unannotated - Black\n",
    "        [255, 255, 255],  # 1: Background - White\n",
    "        [255, 0, 0],      # 2: Tumor epithelium - Red\n",
    "        [255, 165, 0],    # 3: Reactive epithelium - Orange\n",
    "        [0, 255, 0],      # 4: Stroma - Green\n",
    "        [255, 255, 0],    # 5: Inflammation - Yellow\n",
    "        [0, 255, 255],    # 6: Alveolar tissue - Cyan\n",
    "        [255, 192, 203],  # 7: Fatty tissue - Pink\n",
    "        [128, 0, 128],    # 8: Necrotic tissue - Purple\n",
    "        [255, 0, 255],    # 9: Erythrocytes - Magenta\n",
    "        [0, 0, 255],      # 10: Bronchial epithelium - Blue\n",
    "        [165, 42, 42],    # 11: Mucus/Plasma/Fluids - Brown\n",
    "        [128, 128, 128],  # 12: Cartilage/Bone - Gray\n",
    "        [0, 128, 0],      # 13: Macrophages - Dark Green\n",
    "        [128, 0, 0],      # 14: Muscle - Maroon\n",
    "        [255, 20, 147],   # 15: Liver - Deep Pink\n",
    "        [255, 140, 0]     # 16: Keratinization - Dark Orange\n",
    "    ]\n",
    "    \n",
    "    for class_id in range(len(label_map)):\n",
    "        mask = (pred_mask1 == class_id).float()\n",
    "        pred_mask[0] += mask * colors[class_id][0] / 255.0\n",
    "        pred_mask[1] += mask * colors[class_id][1] / 255.0\n",
    "        pred_mask[2] += mask * colors[class_id][2] / 255.0\n",
    "    \n",
    "    # 라벨 마스크 생성 (17개 클래스를 색상으로 매핑)\n",
    "    label_mask1 = torch.argmax(y[0], 0).cpu()\n",
    "    label_mask = torch.zeros((3, img_size, img_size))\n",
    "    \n",
    "    for class_id in range(len(label_map)):\n",
    "        mask = (label_mask1 == class_id).float()\n",
    "        label_mask[0] += mask * colors[class_id][0] / 255.0\n",
    "        label_mask[1] += mask * colors[class_id][1] / 255.0\n",
    "        label_mask[2] += mask * colors[class_id][2] / 255.0\n",
    "    \n",
    "    # 오버레이 생성\n",
    "    normalized_x = (x[0].cpu() + 1.0) / 2.0  # [-1,1] -> [0,1] 변환\n",
    "    label_overlay = normalized_x * 0.7 + label_mask * 0.3\n",
    "    pred_overlay = normalized_x * 0.7 + pred_mask * 0.3\n",
    "\n",
    "    createDirectory('../../results/HnE_Organizational_Segmentation/')\n",
    "    topilimage(torch.concat((label_overlay,pred_overlay),2)).save('../../results/HnE_Organizational_Segmentation/'+str(epoch)+'.jpeg')    \n",
    "if epoch%50==5:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 2, 1) \n",
    "        plt.title('loss_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_loss_list,label='train_loss')\n",
    "        plt.plot(np.arange(epoch+1),val_loss_list,label='test_loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)  \n",
    "        plt.title('acc_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_acc_list,label='train_acc')\n",
    "        plt.plot(np.arange(epoch+1),val_acc_list,label='test_acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "torch.save(model.state_dict(), '../../model/HnE_Organizational_Segmentation/final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44999ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
